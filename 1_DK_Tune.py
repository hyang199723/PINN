#%% Packages# Tune the performance of deep kriging until it is very close to Krigingimport sys#wk_dir = "/r/bb04na2a.unx.sas.com/vol/bigdisk/lax/hoyang/PINN/# wk_dir = 'C://Users//hyang23//PINN//'wk_dir = '/Users/hongjianyang/PINN/'# wk_dir = "/share/bjreich/hyang23/PINN/"sys.path.append(wk_dir)import torchimport matplotlib.pyplot as pltimport pandas as pdimport numpy as npimport randomimport torch.nn as nnimport torch.optim as optimfrom scipy.special import gamma, knif torch.cuda.is_available():    device = torch.device('cuda:2')else:    device = torch.device('cpu')import scipy.stats as statsfrom spde import *import timeprint(device)# %% Replicates# Read datadat = np.array(pd.read_csv(wk_dir + "Data/matern_02_1_1.csv", index_col=False, header = None))original_dimension = (8000, 3, 100)dat_full = dat.reshape(original_dimension)plt.scatter(dat_full[:,0,0], dat_full[:,1,0], s = 20, c = dat_full[:,2,0])# %%iters = 50MSE = []lr = 0.002 # default learning rate in keras adamnnn = 5000 # Numbr of discrete grid of points to evaluate kdelower = -800upper = 800KL_params = [nnn, lower, upper]x = np.linspace(lower, upper, nnn) # Define the range over which to evaluate the KDE and theoretical PDFtheoretical_pdf = norm.pdf(x, 0, 202)rho = 0.2num_centers = [i**2 for i in range(10, 25, 4)] # 1104# Number of layers and neuronslayers = 5neurons = 50eee = 1300for i in range(iters):    print(i)    sub = dat_full[0:7000, :, i]    X = sub[:, 0:2]    Y = sub[:, 2]    X_train, X_val, X_test, y_train, y_val, y_test = random_split_val(X, Y)    model_1, density, W = RBF_train(X_train, X_val, y_train, y_val, lr=lr, epochs=eee, alpha = 0,                          device = device, n_centers=num_centers,                           theory = theoretical_pdf, rho = rho, kl_params = KL_params,                          layers = layers, neurons=neurons)    X_test_tc = torch.tensor(X_test).float().to(device)    y0_model1 = model_1(X_test_tc).cpu().detach().numpy().reshape(-1)    model1_mse = np.mean((y_test - y0_model1)**2)    MSE.append(model1_mse)MSE.to_csv(wk_dir + "HPC/DK/" + "L5N50C1104.csv")